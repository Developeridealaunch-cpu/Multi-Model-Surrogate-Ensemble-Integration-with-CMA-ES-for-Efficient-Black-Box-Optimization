# ğŸŒŒ **Multi-Model Surrogate Ensemble + CMA-ES High-Efficiency Surrogate-Assisted Black-Box Optimization**

ğŸš€ **Overview**

A unified research framework combining multi-model surrogate ensembles with CMA-ES (Covariance Matrix Adaptation Evolution Strategy) â€” designed to drastically reduce expensive evaluations in scientific, simulation, and engineering optimization.

**Core Loop:**

CMA-ES Exploration â†’ Surrogate Prediction â†’ Uncertainty Estimation â†’ Acquisition Ranking â†’
True Evaluation (Top-K) â†’ Surrogate Retraining

âœ¨ **Key Highlights**

**Feature	Description**

ğŸ§© Multi-Model Surrogates	GP, SVR, RBF, Polynomial, MC-Dropout (BNN-like)

âš™ï¸ CMA-ES Integration	Adaptive, global, derivative-free optimizer

ğŸ” Uncertainty-Aware Sampling	UCB, LCB, and EI acquisition

ğŸ§  Novel Algorithms	ESRâ€“CMA-ES â€¢ DAEâ€“SMCâ€“CMA â€¢ MSESâ€“CMA

ğŸ§° Automated Benchmarking	Comparison, visualization, and summary tools

âš¡ Efficiency	5â€“10Ã— fewer expensive evaluations vs classical CMA-ES

ğŸ§‘â€ğŸ’» Extensible	Plug-and-play for new surrogates, encoders, or priors

ğŸ§± **Installation**

**Requirements**

Python â‰¥ 3.11

pip

Setup

pip install -r requirements.txt

(Recommended) Virtual Environment
python -m venv .venv
source .venv/bin/activate      # macOS / Linux
.\.venv\Scripts\activate       # Windows

âš¡ **Quick Start**

# âœ… Verify installation
python -c "print('CMA-ES + Surrogate Framework Ready!')"

# ğŸš€ Run demo optimization
python run_cmaes_surrogate_demo.py --function sphere --dim 5 --max_evals 100

# ğŸ”¬ Compare CMA-ES vs Surrogate-CMA-ES
python run_comparison.py --functions sphere,rastrigin,rosenbrock --dim 3 --runs 5 --max_evals 120 --include_variants

# ğŸ“Š Generate summary metrics
python tools/summarize_results.py --results results --out COMPARISON_RESULTS.csv

ğŸ’¡ **Example Usage**

ğŸ§  **Example 1 â€” Surrogate-Assisted CMA-ES**

from surrogate.surrogate_ensemble import SurrogateEnsemble
from optimizer.cma_es_optimizer import CMAESOptimizer
import numpy as np

def sphere(x): return np.sum(x**2)
bounds = [(-5, 5)] * 3

model = SurrogateEnsemble(input_dim=3, n_models=5)
opt = CMAESOptimizer(dim=3, bounds=bounds, surrogate=model, max_evals=150)
res = opt.optimize(sphere, verbose=True)
print(res["best_x"], res["best_y"])

âš–ï¸ **Example 2 â€” Pure CMA-ES vs Surrogate-CMA-ES**

from optimizer.baselines import pure_cmaes, surrogate_cmaes
import numpy as np

def rastrigin(x):
    return 10 * len(x) + np.sum(x**2 - 10 * np.cos(2*np.pi*x))

print(pure_cmaes(rastrigin, dim=5))
print(surrogate_cmaes(rastrigin, dim=5))

ğŸ§© **Project Structure**

project-root/
â”‚
â”œâ”€â”€ surrogate/
â”‚   â”œâ”€â”€ surrogate_ensemble.py        # Multi-model ensemble
â”‚   â””â”€â”€ gp_model.py                  # Gaussian Process wrapper
â”‚
â”œâ”€â”€ optimizer/
â”‚   â”œâ”€â”€ cma_es_optimizer.py          # CMA-ES core + surrogate integration
â”‚   â”œâ”€â”€ acquisition.py               # EI, UCB, LCB functions
â”‚   â””â”€â”€ baselines.py                 # Pure CMA-ES + baseline methods
â”‚
â”œâ”€â”€ benchmarks/
â”‚   â”œâ”€â”€ sphere.py
â”‚   â”œâ”€â”€ rastrigin.py
â”‚   â””â”€â”€ rosenbrock.py
â”‚
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ summarize_results.py
â”‚   â”œâ”€â”€ plot_results.py
â”‚   â”œâ”€â”€ plot_convergence.py
â”‚   â”œâ”€â”€ novelty_compare.py
â”‚   â””â”€â”€ evaluate_metrics.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ bbob_samples.csv             # Synthetic benchmark dataset
â”‚
â”œâ”€â”€ results/                         # Outputs (CSV + PNG)
â”‚   â”œâ”€â”€ comparison.csv
â”‚   â”œâ”€â”€ convergence_history.csv
â”‚   â”œâ”€â”€ surrogate_metrics.csv
â”‚   â”œâ”€â”€ optimization_metrics.csv
â”‚   â”œâ”€â”€ novelty_performance.csv
â”‚   â””â”€â”€ *.png                        # All plots
â”‚
â”œâ”€â”€ run_cmaes_surrogate_demo.py
â”œâ”€â”€ run_comparison.py
â””â”€â”€ requirements.txt

ğŸ§® **Algorithm Details**

ğŸ”¹ **Surrogate Ensemble**

Models: GP, SVR, RBF, Polynomial, MC-Dropout (BNN-like)

Prediction fusion via weighted mean aggregation

Uncertainty = ensemble variance

Acquisition
=
ğœ‡
âˆ’
ğ‘˜
ğœ
Acquisition=Î¼âˆ’kÏƒ

ğŸ”¹ **CMA-ES Integration**

CMA-ES generates candidate samples

Surrogate predicts & ranks via acquisition

Top-K real evaluations refine CMA-ES covariance

Surrogate retrains periodically

ğŸ“ˆ **Results & Metrics**

ğŸ§  **Surrogate Metrics**

**Metric Meaning**

Ï„	Kendall-Ï„ Rank Correlation
RDE	Relative Distance Error
RMSE	Root Mean Square Error
Corr	Inter-model Consistency
Calibration	Reliability of uncertainty estimation

âš™ï¸ **Optimization Metrics**

**Metric Definition**

ERT	Expected Running Time (evaluations to target)
N_eval	Evaluations to reach global optimum
Best_f(x)	Best solution quality
Success_rate	% of runs reaching target
COCO Visualization	log(FE) vs f(x) curves

ğŸ§ª **Novel Variants (New Contributions)**

<details> <summary>ğŸŒŸ **ESRâ€“CMA-ES â€” Ensemble Surrogate Rank CMA-ES**</summary>

Idea: Aggregates ranks across surrogates for robust candidate selection.
Benefits: Noise-resistant, scale-independent, stable across landscapes.

</details> <details> <summary>ğŸ¤– **DAEâ€“SMC-CMA â€” Dual Adaptive Ensemble + Surrogate Model Control**</summary>

Idea: Two adaptive layers â€” surrogate reliability & CMA-ES evolution control.
Benefits: Prevents overconfidence, dynamically adjusts surrogate trust.

</details> <details> <summary>ğŸŒ **MSES-CMA â€” Multi-Scale Ensemble Surrogate CMA-ES**</summary>

Idea: Multi-scale surrogates for globalâ€“local structure capture.
Benefits: Excellent balance between exploration & exploitation.

</details>

ğŸ§  **Optional Enhancements**

Transformer-Based Embeddings â€” Landscape encoding for structured generalization

Meta-Learned Priors â€” Warm-start surrogate hyperparameters

Adaptive Switching â€” Surrogate trust based on uncertainty & ensemble agreement

ğŸ“Š **Evaluation Outputs**

All results are auto-saved under /results/:

**File Description**

comparison.csv	Method-wise optimization performance
novelty_performance.csv	Novelty vs performance metrics
surrogate_metrics.csv	Surrogate accuracy metrics
optimization_metrics.csv	ERT, success rate, etc.
*.png	Plots: performance, convergence, metrics

ğŸ§© **Dataset**

BBOB-style dataset for surrogate training and testing:
data/bbob_samples.csv â€” 500 samples each for Sphere, Rastrigin, Rosenbrock (3D).

ğŸ§° **Troubleshooting**

Issue	Fix

ImportError	Reinstall dependencies via pip install -r requirements.txt
Slow surrogates	Reduce ensemble size or dimension
Divergent CMA-ES	Ensure finite, ordered bounds
Empty outputs	Check that /results/ contains CSVs

ğŸ¤ **Contributing**

ğŸ’¡ Pull Requests Welcome!

Follow consistent code style

Document new surrogates or acquisition functions

Add reproducible test cases

ğŸ§¾ **License**

This repository is for research and educational use only.
Please cite CMA-ES and surrogate modeling literature in derived publications.

ğŸ§¬ **Citation**

Hansen, N. (2006). The CMA Evolution Strategy: A Comparing Review.
Surrogates in Black-Box Optimization â€” Springer, 2021.
